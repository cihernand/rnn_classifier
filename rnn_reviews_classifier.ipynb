{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332a2ca8",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803dce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import gensim  # para cargar modelo w2v\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a4bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "data = pd.read_csv(\"deceptive-opinion.csv\", usecols=['polarity','text'])\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20711e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to remove punctuation and numbers\n",
    "def remove_puntuacion(text):\n",
    "  \"\"\"Remove puntuación and numbers\"\"\"\n",
    "  new_text = re.sub('[^a-z]+', ' ', text)  \n",
    "  return new_text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lower case\n",
    "data['text'] = data['text'].str.lower()\n",
    "data['text_p'] = data['text'].apply(remove_puntuacion)\n",
    "# Estimate lenght of text review\n",
    "data['text_len'] = data['text_p'].str.split().str.len()\n",
    "data.head(10)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Vocabulary\n",
    "def vocabulary(pandas_series):\n",
    "    lista_palabras = \" \".join(sec for sec in pandas_series).split(\" \")\n",
    "    x = Counter(lista_palabras)\n",
    "\n",
    "    return [i for i,_ in x.most_common() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_words = vocabulary(data['text_p'])\n",
    "vocabulary_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7382e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocabulary  Unique words\n",
    "len(vocabulary_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c481506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map words to tokens\n",
    "\n",
    "def get_dict_map(token_or_tag):\n",
    "    if token_or_tag == 'token':\n",
    "        # agregamos 'PAD_token' al vocabulario de tokens, para ser usado más\n",
    "        # adelante a fin de que todas las oraciones tengan la misma cantidad de\n",
    "        # tokens\n",
    "        vocab = ['PAD_token'] + [token for token in vocabulary(data['text_p']) if token is not None] \n",
    "    elif token_or_tag == 'tag':\n",
    "        vocab = vocabulary(data['Tags'])\n",
    "\n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map('token')\n",
    "print(token2idx['PAD_token'])\n",
    "print(len(token2idx))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_idx'] = data['text_p'].apply(lambda x: list(map(token2idx.get, x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram with reviews lenght\n",
    "data['text_len'].hist(bins=40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b814f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate percentiles\n",
    "custom_percentiles = list(range(5, 101,5))\n",
    "custom_percentile_values = np.percentile(data['text_len'], custom_percentiles)\n",
    "percentile_table = pd.DataFrame({\n",
    "    'Percentile': custom_percentiles,\n",
    "    'Value': custom_percentile_values\n",
    "})\n",
    "print(percentile_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define max lenght\n",
    "max_len = int(data['text_len'].quantile(0.95))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42110d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the entire 'text_idx' column\n",
    "print(\"Contents of data['text_idx']:\")\n",
    "print(data['text_idx'])\n",
    "\n",
    "# Another way to check for None within lists (more concise)\n",
    "print(\"\\nConcise check for None within lists in data['text_idx']:\")\n",
    "has_none = False\n",
    "for index, text_indices in data['text_idx'].items():\n",
    "    if isinstance(text_indices, list) and any(value is None for value in text_indices):\n",
    "        print(f\"List at DataFrame index {index} contains None values.\")\n",
    "        print(data.loc[index]['text_p'])\n",
    "        has_none = True\n",
    "    elif text_indices is None:\n",
    "        print(f\"The entire entry at DataFrame index {index} is None\")\n",
    "        has_none = True\n",
    "\n",
    "if not has_none:\n",
    "    print(\"\\nNo None values found within the lists in data['text_idx'].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.loc[407]['text_idx']\n",
    "print(data.loc[403]['text'])\n",
    "print(data.loc[403]['text_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f383d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "pad_tokens = pad_sequences(data['text_idx'], maxlen= max_len,\n",
    "                           dtype='int32', padding='post',\n",
    "                           value = token2idx['PAD_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66efc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_rnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
